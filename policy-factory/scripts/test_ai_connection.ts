
import ai from '../lib/ai';

async function testConnection() {
    console.log("ü§ñ Testing connection to Local LM Studio...");
    try {
        const completion = await ai.chat.completions.create({
            messages: [{ role: "user", content: "Hello! Are you ready to validate policies?" }],
            model: "local-model", // LM Studio ignores this usually
        });

        console.log("‚úÖ AI Response:", completion.choices[0].message.content);
    } catch (error) {
        console.error("‚ùå Connection Failed:", error);
        console.log("üí° Tip: Ensure LM Studio is running inside the 'Local Server' tab on port 1234.");
    }
}

testConnection();
